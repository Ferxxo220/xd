import gradio as gr
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import io
import base64
import os
import requests
from dotenv import load_dotenv
import warnings
import nbformat
from nbformat.v4 import new_notebook, new_code_cell, new_markdown_cell
from github import Github, GithubException # <--- NUEVO IMPORT PARA GITHUB

# Suprimir advertencias de Matplotlib/Pandas
warnings.filterwarnings("ignore")

# -------------------------------------------------------
# 1. CONFIGURACI√ìN DE OLLAMA Y ENTORNO
# -------------------------------------------------------
load_dotenv(override=True)

OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434") 
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral") 

# Credenciales de GitHub (Nuevas variables)
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN") 
GITHUB_REPO_NAME = os.getenv("GITHUB_REPO_NAME") # Formato: "usuario/repo"

# -------------------------------------------------------
# 2. FUNCIONES DE OLLAMA (CORE LLM)
# -------------------------------------------------------
def query_ollama(prompt: str) -> str:
    """Consulta el modelo de Ollama para la l√≥gica de razonamiento."""
    print(f"DEBUG: Llamando a Ollama...")
    try:
        response = requests.post(
            f"{OLLAMA_BASE_URL}/api/generate",
            json={
                "model": OLLAMA_MODEL, 
                "prompt": str(prompt), 
                "stream": False, 
                "options": {"temperature": 0.1}
            },
            timeout=120
        )
        response.raise_for_status() 
        return response.json()["response"]
    except requests.exceptions.RequestException as e:
        print(f"‚ùå ERROR CR√çTICO DE CONEXI√ìN OLLAMA: {e}")
        return "Error: Ollama no est√° disponible."


# -------------------------------------------------------
# 3. FUNCIONES DE GITHUB (NUEVO)
# -------------------------------------------------------
def upload_notebook_to_github(file_path: str) -> str:
    """Sube el archivo .ipynb generado a GitHub autom√°ticamente."""
    if not GITHUB_TOKEN or not GITHUB_REPO_NAME:
        return "‚ö†Ô∏è **GitHub no configurado:** No se subi√≥ el archivo (faltan credenciales en .env)."

    try:
        g = Github(GITHUB_TOKEN)
        repo = g.get_repo(GITHUB_REPO_NAME)
        
        file_name = os.path.basename(file_path)
        
        # Leemos el archivo binario
        with open(file_path, "rb") as file:
            content = file.read()
        
        # Crear archivo en el repo (carpeta 'notebooks_generados')
        path_in_repo = f"notebooks_generados/{file_name}"
        
        repo.create_file(
            path=path_in_repo,
            message=f"Auto-upload: An√°lisis generado por Agente AI - {file_name}",
            content=content
        )
        
        repo_url = f"https://github.com/{GITHUB_REPO_NAME}"
        return f"‚úÖ **Guardado en GitHub:** El notebook se subi√≥ exitosamente a `{path_in_repo}`.\n[Ver Repositorio]({repo_url})"
        
    except GithubException as e:
        return f"‚ùå **Error GitHub:** No se pudo subir el archivo. Detalles: {e.data.get('message', e)}"
    except Exception as e:
        return f"‚ùå **Error General GitHub:** {str(e)}"


# -------------------------------------------------------
# 4. FUNCIONES DE DATA SCIENCE (TOOLS)
# -------------------------------------------------------

def create_and_save_notebook(title: str, file_name: str, code_cells: list, markdown_cells: list):
    """Crea y guarda un archivo Jupyter Notebook (.ipynb)."""
    nb = new_notebook()
    nb['cells'] = []

    nb['cells'].append(new_markdown_cell(f"# {title}\n\n**Archivo Original:** `{file_name}.csv`\n\n**Generado por:** Agente de An√°lisis."))

    for md, code in zip(markdown_cells, code_cells):
        nb['cells'].append(new_markdown_cell(md))
        nb['cells'].append(new_code_cell(code))

    timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
    safe_name = file_name.replace(" ", "_").replace(".", "_")
    ipynb_filename = f"{safe_name}_{timestamp}_Reporte.ipynb"
    filepath = os.path.join(os.getcwd(), ipynb_filename)

    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            nbformat.write(nb, f)
        print(f"‚úÖ Notebook guardado localmente: {filepath}")
        return filepath
    except Exception as e:
        print(f"‚ùå Error al guardar Notebook local: {e}")
        return None

# --- 1) Estad√≠stica Descriptiva (MEJORADA CON DESCRIPCI√ìN) ---
def get_descriptive_statistics(csv_content: str, file_name: str = "data") -> dict:
    try:
        df = pd.read_csv(io.StringIO(csv_content))
    except Exception as e:
        return {"status": "error", "report_text": f"Error CSV: {e}"}

    stats = df.describe(include="all").to_string()
    
    # --- NUEVA L√ìGICA: INTERPRETACI√ìN CON OLLAMA ---
    print("‚è≥ Solicitando interpretaci√≥n de datos a Ollama...")
    prompt_interpretacion = (
        f"Act√∫a como un Cient√≠fico de Datos experto. Aqu√≠ tienes las estad√≠sticas descriptivas de un dataset llamado '{file_name}':\n"
        f"{stats}\n\n"
        "Escribe un breve p√°rrafo (m√°x 5 l√≠neas) interpretando los hallazgos m√°s importantes para un usuario de negocio. "
        "S√© directo. No menciones c√≥digo, solo insights sobre los datos."
    )
    interpretacion = query_ollama(prompt_interpretacion)
    # -----------------------------------------------

    # Gr√°fica
    fig = plt.figure(figsize=(10, 6))
    ax = fig.gca()
    try:
        df.select_dtypes(include=[np.number]).hist(ax=ax)
        plt.tight_layout()
    except:
        pass

    # Generaci√≥n Notebook
    code_load = f"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# df = pd.read_csv('{file_name}.csv')\nprint('Datos cargados')"
    code_stats = "print(df.describe(include='all').to_string())"
    code_hist = "df.select_dtypes(include=['number']).hist(figsize=(10, 6))\nplt.show()"
    
    ipynb_path = create_and_save_notebook(
        title=f"Estad√≠stica - {file_name}",
        file_name=f"{file_name}_Stats",
        code_cells=[code_load, code_stats, code_hist],
        markdown_cells=["## Carga", "## Estad√≠sticas", "## Gr√°ficas"]
    )

    # Reporte mejorado con la interpretaci√≥n
    report_text = (
        f"### üìä Estad√≠stica Descriptiva: **{file_name}**\n\n"
        f"#### üß† **An√°lisis del Agente:**\n> {interpretacion}\n\n"
        "#### **Tabla de Datos:**\n"
        f"```\n{stats}\n```\n"
    )
    
    return {"status": "success", "report_text": report_text, "plot_figure": fig, "path": ipynb_path}


# --- 2) Preprocesamiento de Datos ---
def perform_data_preprocessing(csv_content: str, file_name: str = "data") -> dict:
    try:
        df = pd.read_csv(io.StringIO(csv_content))
    except Exception as e:
        return {"status": "error", "report_text": f"Error CSV: {e}"}

    nulos_antes = df.isna().sum().to_string()
    
    for col in df.columns:
        if df[col].dtype in [int, float, np.float64, np.int64]:
            df[col] = df[col].fillna(df[col].mean()) 
        else:
            df[col] = df[col].fillna(df[col].mode()[0] if df[col].mode().size else "")
    
    nulos_despues = df.isna().sum().to_string()
    
    fig = plt.figure(figsize=(8, 6))
    try:
        corr_matrix = df.select_dtypes(include=[np.number]).corr() 
        if not corr_matrix.empty and len(corr_matrix.columns) > 1:
            plt.imshow(corr_matrix, interpolation='nearest', cmap='coolwarm')
            plt.title('Matriz de correlaci√≥n')
            plt.colorbar()
            plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=90)
            plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns)
        else:
            plt.text(0.5, 0.5, "No hay suficientes datos num√©ricos", ha='center')
    except:
        pass

    # Notebook
    code_load = f"import pandas as pd\nimport numpy as np\n# df = pd.read_csv('{file_name}.csv')"
    code_imp = "# Imputaci√≥n de nulos (Mean/Mode)...\ndf = df.fillna(0) # Simplificado"
    code_corr = "print(df.corr())"

    ipynb_path = create_and_save_notebook(
        title=f"Preprocesamiento - {file_name}",
        file_name=f"{file_name}_Prep",
        code_cells=[code_load, code_imp, code_corr],
        markdown_cells=["## Carga", "## Imputaci√≥n", "## Correlaci√≥n"]
    )

    report_text = (
        f"### üßπ Preprocesamiento: **{file_name}**\n\n"
        "#### **Resumen de Cambios:**\n"
        f"Nulos corregidos autom√°ticamente (Num√©ricos: Promedio | Texto: Moda).\n\n"
        f"**Nulos Antes:**\n```\n{nulos_antes}\n```\n"
        f"**Nulos Despu√©s:**\n```\n{nulos_despues}\n```\n"
    )
    
    return {"status": "success", "report_text": report_text, "plot_figure": fig, "path": ipynb_path}


# -------------------------------------------------------
# 5. L√ìGICA PRINCIPAL (AGENTE)
# -------------------------------------------------------

def get_agent_capabilities() -> str:
    return (
        "## üöÄ Agente de Datos con GitHub + IA\n\n"
        "1. **Estad√≠stica Descriptiva:** Genera tabla, histogramas y **una explicaci√≥n IA de los datos**.\n"
        "2. **Preprocesamiento:** Limpia nulos y muestra correlaciones.\n\n"
        "üì¶ *Los notebooks generados se subir√°n autom√°ticamente a tu GitHub si est√° configurado.*"
    )

def analyze_csv_agent(user_prompt: str, uploaded_file):
    if uploaded_file is None:
        if any(x in user_prompt.lower() for x in ['hola', 'opciones', 'que haces']):
            return get_agent_capabilities(), None, None
        return "‚ùå Sube un CSV primero.", None, None

    try:
        with open(uploaded_file.name, 'r', encoding='utf-8') as f:
            csv_content = f.read()
        file_name = os.path.basename(uploaded_file.name).split('.')[0]
    except Exception as e:
        return f"‚ùå Error lectura: {e}", None, None

    # Razonamiento LLM
    llm_prompt = f"Comando: '{user_prompt}'. Responde SOLO 'OPCION: 1' (Estad√≠stica) o 'OPCION: 2' (Limpieza/Preproceso)."
    llm_response = query_ollama(llm_prompt).strip().upper()

    if "1" in llm_response:
        result = get_descriptive_statistics(csv_content, file_name)
    elif "2" in llm_response:
        result = perform_data_preprocessing(csv_content, file_name)
    else:
        return f"ü§î No entend√≠ la orden. Intenta: 'Analiza la estad√≠stica' o 'Limpia los datos'.", None, None

    # --- INTEGRACI√ìN GITHUB ---
    github_message = ""
    if result.get("status") == "success" and result.get("path"):
        print(f"Intentando subir a GitHub: {result.get('path')}")
        github_message = upload_notebook_to_github(result.get("path"))
    
    # Armar respuesta final
    final_report = result.get("report_text", "Error") + "\n\n---\n" + github_message
    
    return final_report, result.get("plot_figure"), result.get("path")


# -------------------------------------------------------
# 6. DEFINICI√ìN DE INTERFAZ GRADIO
# -------------------------------------------------------
with gr.Blocks(title="Agente AI + GitHub") as demo:
    gr.Markdown("# üìä Agente de An√°lisis de Datos (Ollama + GitHub)")
    
    with gr.Row():
        prompt_input = gr.Textbox(label="Instrucci√≥n", placeholder="Ej: 'Analiza la estad√≠stica y expl√≠came los datos'", lines=2)
        file_input = gr.File(label="CSV", file_types=[".csv"])
        
    analyze_button = gr.Button("üöÄ Ejecutar Agente", variant="primary")
    
    output_message = gr.Markdown(label="Resultados", value=get_agent_capabilities())
    output_plot = gr.Plot(label="Visualizaci√≥n")
    output_file = gr.File(label="Notebook Local (.ipynb)", interactive=False)

    analyze_button.click(
        fn=analyze_csv_agent, 
        inputs=[prompt_input, file_input], 
        outputs=[output_message, output_plot, output_file]
    )

# NOTA: No incluimos .launch() aqu√≠ porque lo lanzamos desde main.py con FastAPI
